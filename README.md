# trash


# Формирование требований к алгоритму машинного обучения для оценки достоверности научных утверждений в исследовательских ресурсах

Ключевые слова: Каузальная Байесовская машина, алгоритм машинного обучения, наборы данных, причинно-следственная связь, каузальность.

## Аннотация

В статье был проведен обзор аналогов, которые могли бы решить задачу оценивания достоверности научных утверждений. В качестве аналогов использовались такие алгоритмы, как  LIME, KernelShap, TreeShap, Anchors, LRP. В силу отсутствия одного/нескольких критериев у аналогов, таких как наличие справедливого распределения, выведение стабильного результата, использование регуляризации, а также умение определения причинно-следственных связей, было выявлено, что ни один из аналогов не позволяет в полной мере решить задачу оценки достоверности научных утверждений. Также, было проведено составление архитектуры для алгоритма машинного обучения и изучение концепции Каузальной Байесовской машины с определением её применимости в контексте данной задачи. Результатом являются требования, составленные по критериям при сравнении аналогов, по исследованию концепции Каузальной Байесовской машины, а также по сформированной архитектуре алгоритма машинного обучения. Разработанные требования позволяют в полной мере реализовать алгоритм машинного обучения для оценки достоверности научных утверждений в исследовательских ресурсах.

## Введение

В настоящее время существует множество научных журналов, статей, содержащих противоречивые утверждения, сформированные при исследовании различных наборов данных. Например, на CNN Health была опубликована статья [1], в которой утверждается, что чрезмерное употребление кофе людьми моложе 55 лет связано с их ранней смертью, при этом существует другая статья [2], где говорится о том, что употребление кофе не влияет на смертность. На данный момент времени альтернативное решение задачи проверки достоверности утверждений, опубликованных в СМИ разного уровня публичности, может быть получено с помощью таких алгоритмов искусственного интеллекта, как Lime, Shap или Anchors. Однако, ни в одном из них не используется причинно-следственная связь для решения поставленной задачи, что, в свою очередь, снижает точность результатов, полученных с помощью обработки этими алгоритмами. Таким образом, алгоритмы Lime, Shap и Anchors уступают качеством полученных результатов, по сравнению с алгоритмом работы Каузальной Байесовской машины, чья основа лежит в использовании причинно-следственного вывода.
Целью исследования является формирование требований для алгоритма оценки достоверности научных утверждений, содержащихся в исследовательских ресурсах, с помощью модели машинного обучения на основе каузальной Байесовской машины.
Объектом исследования являются наборы данных, приведенные в исследовательских ресурсах. Предметом исследования является достоверность выводов в процентах на основе  наборов данных, приведенных в исследовательских ресурсах.

Для создания списка требований предполагается решение следующих задач:
1. Изучение алгоритма работы Каузальной Байесовской машины
2. Сравнение модели машинного обучения на основе Каузальной Байесовской машины с аналогичными алгоритмами машинного обучения
3. Формирование требований для алгоритма работы Каузальной Байесовской машины

## Обзор предметной области

### Принцип отбора аналогов

Отбор аналогов, представляющих собой конкретные методы интерпретации машинного обучения, решающие проблему проверки на противоречивость научных утверждений, основанных на результатах обработки наборов данных в исследовательских ресурсах, производился с помощью поиска по следующим ключевым словосочетаниям и словам:

Поиск на русском языке:
* Методы интерпретации машинного обучения
* Использование машинного обучения для анализа наборов данных
* Эффективность Байесовского метода в машинном обучении

Поиск на английском языке:
* CausalAI
* Causality
* LIME
* SHAP
* KernelSHAP
* TreeSHAP
* Anchors
* Layer-wise Relevance Propagation

### Определение критериев оценки аналогов

Были выбраны следующие критерии для оценки аналогов методов интерпретации машинного обучения
* Наличие справедливого распределения прогноза
* Наличие стабильности результата
* Наличие регуляризации
* Умение определения причинно-следственных связей во время выполнения работы

#### Наличие справедливого распределения прогноза
Предвзятость алгоритма машинного обучения - Закрепление неверных паттернов при анализе входных наборов данных. Пример предвзятости алгоритма машинного обучения: В 2015 году сервис Google Photo идентифицировал двух афроамериканцев как горилл [3]. Справедливость предполагает исправление предвзятости алгоритма машинного обучения. Таким образом, наличие справедливого распределения было выбрано, так как при его использовании устраняется предвзятость алгоритма модели машинного обучения по отношению к конфиденциальным атрибутам. Справедливое распределение может присутствовать, отсуствовать, а также не быть гарантированным, в силу погрешности работы модели машинного обучения.


#### Наличие стабильности результата
Наличие стабильности результата было выбрано в силу необходимости исправности работы модели машинного обучения. При нескольких обработках алгоритмом машинного обучения на одном и том же наборе данных необходим однозначный результат для точного утверждения о противоречивости научных утверждений в исследовательских ресурсах. В случае отсутствия стабильности, модель машинного обучения будет обрабатывать данные с погрешностью, а это, в свою очередь, может привести к тому, что верные научные утверждения, приведенные в статье, будут считаться неверными.

#### Наличие регуляризации
Переобучение предполагает, что модель корректно обрабатывает набор данных, который был дан при обучении, при этом может неверно работать с набором из пробных данных, в силу установления устойчивых закономерностей.
Данный критерий был выбран, поскольку регуляризация способствует уменьшению степени переобучения модели, что, в свою очередь, повышает точность результатов обработки моделью машинного обучения, путём добавления дополнительных ограничений к условиям выполнения алгоритма (например, добавление штрафа за сложность модели).


#### Умение определения причинно-следственных связей во время выполнения работы
Корреляция предполагает связь между переменными, которые изменяются схожим образом, а каузальность (англ. Causal - Причинность) - это общая связь между причиной, и порождающимся ей следствием [4]. При этом, расчеты коэффициентов корреляции не позволяют определить, какой из признаков, участвующих в анализе, является причиной, а какой следствием. Корреляция может показать, что два признака связаны между собой, но она не дает ответа на вопрос, почему они связаны [5]. Таким образом, увеличивается вероятность того, что корреляция без определения причинно-следственных связей будет ложной в силу игнорирования факторов, дающих дополнительную информацию об обозреваемом явлении, что в свою очередь негативно влияет на точность результата обработки моделью машинного обучения, поэтому умение определения причинно-следственных связей во время выполнения работы было выбрано в качестве критерия.
Эффективность для обработки результата модели при определении причинно-следственных связей представлена в исследовании точности медицинского диагноза с помощью каузального машинного обучения [6]. В данном исследовании показано, что при использовании алгоритма, определяющего причинную-следственную связь для k > 5 (где k - максимальная ошибка алгоритма), уменьшается количество ошибочных диагнозов примерно на 30% по сравнению использованием ассоциативного метода, применяющего исключительно корреляцию для прогнозирования при тех же значениях k [6].

### Краткое описание аналогов

#### LIME

LIME(англ. Local surrogate models, рус. Локальные суррогатные модели) - это интерпретируемые модели, которые используются для объяснения отдельных прогнозов моделей машинного обучения "черного ящика". Суррогатные модели обучаются для аппроксимации прогнозов базовой моде
ли черного ящика. Вместо обучения глобальной суррогатной модели LIME фокусируется на обучении локальных суррогатных моделей для объяснения индивидуальных прогнозов [7].

#### SHAP

SHAP (англ. SHapley Additive exPlanations, рус. аддитивные объяснения Shapley) - это метод для объяснения индивидуальных прогнозов. SHAP основан на игре теоретически оптимальных значений Shapley [8].

##### KernelSHAP

KernelSHAP — это независимый от модели метод для аппроксимации значений SHAP с использованием идей из значений LIME и Shapley. KernelSHAP оценивает вклад каждого значения функции в прогноз для экземпляра «x». KernelSHAP состоит из пяти шагов: проверка коалиций, получение прогноза для каждой коалиции, вычисление веса для каждой из них с использованием ядра SHAP, создание взвешенной линейной модели и возвращение значений Шепли «k», коэффициентов линейной модели [8].

##### TreeSHAP

Tree SHAP — это метод оценки значений SHAP для моделей деревьев и леса при нескольких различных возможных предположениях о зависимости признаков. Скорость работы алгоритма зависит от быстрых реализаций C++ либо внутри пакета внешней модели, либо в локально скомпилированном расширении C [9].

#### Anchors

Метод Anchors интерпретирует индивидуальные предсказания любой модели классификации черного ящика путем нахождения решающего правила, которое в достаточной степени “закрепляет” предсказание. Правило закрепляет прогноз, если изменения в значениях других объектов не влияют на него. Anchors использует методы обучения с подкреплением в сочетании с алгоритмом поиска по графу, чтобы сократить количество вызовов модели (и, следовательно, требуемое время выполнения) до минимума, сохраняя при этом возможность восстановления после локальных оптимумов. Рибейро, Сингх и Гестрин предложили алгоритм в 2018 году – те же исследователи, которые представили алгоритм LIME [10].

#### LRP

LRP(англ. Layer-wise relevance, рус. Послойное распространение релевантности) - один из методов объяснимого машинного обучения, означающий, что величина любого выхода y сохраняется в процессе обратного распространения и равна сумме карт релевантности R входного слоя. Это свойство выполняется для любых последовательных слоев j и k и по транзитивности для входного и выходного слоев [11].

### Таблица сравнения по критериям


Cравнение аналогов по приведённым выше критериям представлен в табл. 1.


Таблица 1 - Сравнение аналогов по критериям

| Аналог | Наличие справедливого распределения прогноза | Наличие стабильности результата | Наличие регуляризации |
|:---------------------------:|:---------------------------:|:------------------:|:--:|
| LIME | Не гарантирует | - | + |
| TreeSHAP | Присутствует | + | - |
| KernelSHAP | Присутствует | + | + |
| Anchors | Отсуствует | + | + |
| LRP | Присутствует | + | + |

### Выводы по итогам сравнения
По итогам проведения сравнения, было выявлено, что все аналоги из выше перечисленных, кроме LIME обладают стабильностью результата.
Также, было отмечено, что LIME не гарантирует наличие справедливого распределения прогноза, а у Anchors оно отсутствует.
Каждый из выше перечисленных алгоритмов машинного обучения обладает регуляризацией, кроме TreeSHAP.
При этом каждый из приведенных выше аналогов не обладает умением определения причинно-следственных связей для решения задачи оценки проверки научных утверждений в исследовательских ресурсах. Данный отсутствующий параметр является необходимым, поскольку он гарантирует причинность следствий для прогнозируемых значений при обработке входного набора данных, избегая при этом формирования ложных корреляций.
Выявление недостатков каждого из рассмотренных аналогов позволяет сформировать требования, представленные в разделе "Выбор метода решения".

## Выбор метода решения

Разрабатываемое решение - требования для алгоритма оценки достоверности научных утверждений, содержащихся в исследовательских ресурсах, с помощью модели машинного обучения на основе каузальной Байесовской машины. Разрабатываемое решение должно гарантировать для алгоритма работы модели машинного обучения корректную обработку наборов данных с последующим выводом достоверности проверяемого научного утверждения, оцениваемого в процентах.

При сравнении аналогов был сделан вывод о необходимости следующих критериев в разрабатываемых требованиях для алгоритма машинного обучения:
- Наличие справедливого распределения прогноза для устранения предвзятости алгоритма модели машинного обучения по отношению к конфиденциальным атрибутам
- Наличие стабильности результата, поскольку результат обработки моделью машинного обучения при проверке статей на протеворечивость должен быть однозначным.
- Наличие регуляризации для того чтобы модель была отказоустойчива к переобучению.
- Умение определения причинно-следственных связей во время выполнения работы алгоритма для предотвращения формирования ложных корреляций, которые могут быть выявлены в силу игнорирования факторов, дающих дополнительную информацию об обозреваемом явлении.

Модель машинного обучения, предполагающая выполнение всех требований в соответствии с разрабатываемым решением, будет иметь более высокую точность оценки достоверности научных утверждений, чем аналоги, в силу соблюдения всех критериев, приведенных выше. Например, если научные утверждения будут содержать медицинские исследования, касаемые изучения связей диагнозов заболеваний, то количество ошибочных диагнозов, посчитанное моделью в процессе работы, будет меньше на 30% при k > 5 (где k - максимальная ошибка алгоритма), чем при обработке аналогами [6], таким образом положительно влияя на точность результата. При этом, результат будет однозначным, с учётом конфиденциальных атрибутов, а сама модель будет устойчива к переобучению.

## Описание метода решения

### Реализация

Алгоритм машинного обучения должен быть реализован с помощью языка программирования Python [12]. Python был выбран, поскольку он обладает широкой совместимостью, а также, на нем уже реализованы библиотеки, содержащие необходимые инструменты для программирования искусственного интеллекта. Алгоритм при реализации должен использовать следующие библиотеки Python:
- NumPy [15], для выполнения численных операций, в том числе линейной алгебры.
- Scikit-Learn [16], для выполнений статистических операций, таких как, например, вычисление корреляции.
- Dask [13], для работы с табличными данными. Аналогами данного инструмента для Python являются Pandas [17] и Vaex [18]. Pandas интегрируется вместе с библиотеками NumPy и Scikit-Learn, однако он не может хранить большие объемы данных, размер которых может достигать 100 гб. Vaex, в свою очередь, способен хранить 100 гб данных, однако не может работать вместе с библиотеками NumPy и Scikit-Learn.

Входными значениями для модели являются: множество табличных наборов данных и утверждение в виде логического выражения. Выходными значениями являются: число в процентах, представляющее собой оценку достоверности логического выражения, и граф принятия решений моделью. Алгоритм машинного обучения должен обрабатывать входные данные в соответствии с концепцией Каузальной Байесовской машины.

### Каузальная Байесовская машина
Каузальная Байесовская машина - концепция для метода машинного обучения, в основе которой лежит структурно-причинная модель (англ.  Structural Causal Model, SCM).

Контрфактуал - это выражение вида $$Y_x(u) = y$$, предполагающее следующий смысл: "Y было бы y, в случае если бы X был x для ситуации, когда U = u" [14]. В данном случае X, Y - являются переменными для столбцов таблицы x, y конкретного набора данных; U - переменная для u, предполагающая фоновое условие, для которого модель ещё не определила объяснительный механизм.

SCM - Каузальная контрфактическая структура с использованием причинно-следственного графа для кодирования научных предположений, в которой свойствами структурных уравнений являются контрфактуалы, нужные для задания вопросов модели на языке машинного обучения [14]. Данная структура должна использоваться для объединения тех наборов данных, которые по причинно-следственной связи подходят для решения модели. Кроме того, эта структура необходима для устранения следующих предвзятостей:
- Предвзятости по отношению к выбору набора данных из имеющихся входных
- Спутывающей предвзятости. В данном случае предполагается статистическая предвзятость, которая влияет на зависимые и независимые переменные, в результате реализуя ложную зависимость.

Структура SCM придерживается следующих принципов причинного вывода:

1) Закон структурных контрфактуалов. В данном случае, принцип описывает семантику контрфактуалов для их вычисления и вытекающих из них вероятностей, как из текущего состояния модели, так и из наблюдаемых данных [14]. Данный принцип нужен для определения того, каким образом необходимо связать исходные наборы данных для решения проблемы предвзятости к выбору этих наборов.

2) Закон структурной независимости, определяющий то, как особенности создаваемой модели повлияют на наблюдаемые данные. Предполагается разделение двух наборов данных с помощью третьего, таким образом создавая связь между причинными предположениями [14]. Данная связь помогает оценивать эффект вмешательства, тем самым преодолевая проблему спутывающей предвзятости.

Корректное объединение наборов данных с последующим избавлением от предвзятостей, описанных выше, положительно влияет на правильность обработки входных данных, тем самым повышая точность оценки проверки исследуемого утверждения.

Использование данной структуры для построения модели машинного обучения также даёт следующие возможности:
- контроль того, как модель принимает логические решения;
- просмотр разветвления предположений, созданные моделью;
- анализ формирования поведения модели при внешнем вмешательстве.

Данные возможности позволяют отобразить пути принятия решений модели с помощью графа, который нужен для вывода подробного доказательства моделью научного утверждения, приведённого в статье. Графовое представление нужно для человекочитаемости вывода.


### Сформированные требования
В результате были сформированы следующие требования:
- Алгоритм использует язык программирования Python
- Входными значениями для модели являются: Множество наборов данных и логическое выражение
- Алгоритм взаимодействует с следующими библиотеками: NumPy, Dask, Scikit-Learn
- Алгоритм машинного обучения должен быть основан на SCM
- Выходными значениеми для модели являются: число в процентах, представляющее собой оценку достоверности логического выражения и граф принятия решений.

## Заключение
В ходе выполнения исследования были выполнены все поставленные задачи, а именно: 
1) Было проведено изучение алгоритма работы Каузальной Байесовской машины. В ходе изучения, были выявлены особенности и возможности, которыми будет обладать алгоритм машинного обучения для анализа наборов входных табличных данных, а также определена их значимость и применимость в контексте решения задачи проверки научных статей на противоречивость.
2) Произведен поиск с последующим сравнением аналогов, представленного в пункте "Обзор предметной области". В качестве аналогов были выбраны следующие алгоритмы машинного обучения: LIME, KernelShap, TreeShap, Anchors, LRP. В ходе сравнения было выявлено, что по эффективности рассматриваемые аналоги уступают алгоритму с разрабатываемыми требованиями из-за отсутствия одного или нескольких критериев, среди которых:
- Наличие справедливого распределения прогноза
- Наличие стабильности результата
- Наличие регуляризации
- Умение определения причинно-следственных связей.

3) Сформулированы требования для алгоритма машинного обучения исходя из цели работы, результатов сравнения аналогов, а также особенностей работы Каузальной Байесовской машины:
- Алгоритм должен использовать язык программирования Python
- Модель должна принимать следующие входные значения: Множество наборов табличных данных и логическое выражение
- Алгоритм должен использовать следующие библиотеки: NumPy, Dask, Scikit-Learn
- Алгоритм машинного обучения должен быть основан на структуре SCM. Данное требование учитывает наличие справедливого распределения прогноза и умение определения причинно-следственных связей
- После обработки данных модель должна выдавать в качестве результата число в процентах, представляющее собой оценку достоверности логического выражения, а также визуальное представление графа принятия решений
- Результат алгоритма машинного обучения должен быть стабильным
- Алгоритм должен иметь регуляризацию.

В дальнейшем, будет проведена разработка алгоритма, удовлетворяющего сформулированным требованиям. После разработки будет произведен анализ, касающийся уменьшения потребления памяти и алгоритмической сложности работы алгоритма.


## Список использованных источников

[1] Junxiu Liu,Xuemei Sui,Carl J. Lavie,James R. Hebert,Conrad P. Earnest,Jiajia Zhang,Steven N. Blair, Association of Coffee Consumption With All-Cause and Cardiovascular Disease Mortality [Электронный ресурс] URL: https://www.mayoclinicproceedings.org/article/S0025-6196(13)00578-8/fulltext. (дата обращения: 10.11.2022).

[2] ESC Press Office, Coffee drinking is associated with increased longevity [Электронный ресурс] URL: https://www.eurekalert.org/news-releases/965928 (дата обращения: 10.11.2022).

[3] Barr A.Google Mistakenly Tags Black People as 'Gorillas', Showig Limits of Algorithms // The Wall Street Journal. 2015. №1. URL: https://www.wsj.com/articles/BL-DGB-42522 (дата обращения: 30.11.2022).

[4] Guo R., Cheng L.,Li J., Hahn P.R. A Survey of Learning Causality with Data: Problemsand Methods [Электронный ресурс], URL: https://arxiv.org/abs/1809.09337 (дата обращения: 30.11.2022).

[5] Илышев А.М., Общая теория статистики [Электронный ресурс], URL: https://bstudy.net/672083/sotsiologiya/korrelyatsiya_prichinnost (дата обращения: 30.11.2022).

[6] Richens JG, Lee CM, Johri S. Improving the accuracy of medical diagnosis with causal machine learning. Nat Commun. 2020 Aug 11;11(1):3923. doi: 10.1038/s41467-020-17419-7. Erratum in: Nat Commun. 2020 Sep 16;11(1):4754. Erratum in: Nat Commun. 2021 Mar 31;12(1):2108. PMID: 32782264; PMCID: PMC7419549 (дата обращения: 30.11.2022).

[7] LIME, Molnar, Christoph. Interpretable machine learning. Lulu. com, 2022. sec 9.2 [Электронный ресурс], URL: https://christophm.github.io/interpretable-ml-book/lime.html (дата обращения: 30.11.2022).

[8] SHAP, Molnar, Christoph. Interpretable machine learning. Lulu. com, 2022. sec 9.6 [Электронный ресурс], URL: https://christophm.github.io/interpretable-ml-book/shap.html (дата обращения: 30.11.2022).

[9] API Reference, shap.explainers.Tree [Электронный ресурс], URL: https://shap.readthedocs.io/en/latest/generated/shap.explainers.Tree.html (дата обращения: 30.11.2022).

[10] Anchors, Molnar, Christoph. Interpretable machine learning. Lulu. com, 2022. sec 9.4 [Электронный ресурс], URL: https://christophm.github.io/interpretable-ml-book/anchors.html (дата обращения: 30.11.2022).

[11] Alexander Binder, Gr´egoire Montavon, Sebastian Bach, Klaus-Robert M¨uller, and Wojciech Samek. ILayer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers [Электронный ресурс], URL: https://arxiv.org/pdf/1604.00825.pdf (дата обращения: 30.11.2022).

[12] Python Documentation [Электронный ресурс]. URL: https://www.python.org/doc/ (дата обращения: 19.12.2022).

[13] Dask Documentation API Reference [Электронный ресурс]. URL: https://docs.dask.org/en/stable/develop.html (дата обращения: 19.12.2022).

[14] Elias Bareinboim and Judea Pearl, Causal inference and the data-fusion problem (дата обращения: 19.12.2022).

[15] NumPy [Электронный ресурс]. URL: https://numpy.org/ (дата обращения: 20.12.2022).

[16] Scikit-Learn [Электронный ресурс]. URL: https://scikit-learn.org/stable/ (дата обращения: 20.12.2022).

[17] Pandas [Электронный ресурс]. URL: https://pandas.pydata.org/ (дата обращения: 21.12.2022).

[18] Vaex [Электронный ресурс]. URL: https://vaex.io/ (дата обращения: 21.12.2022).
